{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4dc6386-ca0a-4477-8610-999300c197c7",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52fd215a-ab9c-46ef-bebd-16eda56cf8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relativePath = \"../data/kawintiranon-stance-detection/\" \n",
    "file = \"biden_stance_train_public.csv\"\n",
    "path = relativePath + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f72231-a9d8-4489-8b2b-2146747d3d5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file):\n",
    "    relativePath = \"../data/kawintiranon-stance-detection/\"\n",
    "    return pd.read_csv(relativePath+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db0c9440-2353-497d-974b-84f2fc2feb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower()\n",
    "    text = re.sub(r'#[^ ]+', '', text)  # removing hashtags\n",
    "    text = re.sub(r'https.+', '', text)  # removing links\n",
    "    text = re.sub(r'@[^ ]+', '', text)  # removing mentions\n",
    "    text = re.sub(r'[^(a-zA-Z)\\s]', '', text) # removing special characters\n",
    "    return text\n",
    "\n",
    "def filter_stopwords_and_lemmatize(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    words = text.split() \n",
    "    filtered_words = [word for word in words if word not in stopwords] \n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    return \" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e88ecae-2087-49ae-bdce-8d506231c370",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "biden_train = load_dataset(\"biden_stance_train_public.csv\")\n",
    "trump_train = load_dataset(\"trump_stance_train_public.csv\")\n",
    "\n",
    "biden_test = load_dataset(\"biden_stance_test_public.csv\")\n",
    "trump_test = load_dataset(\"trump_stance_test_public.csv\")\n",
    "\n",
    "all_datasets = [biden_train, trump_train, biden_test, trump_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95b8269a-aa87-4133-ab07-4b779e44d040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1311162417938919424</td>\n",
       "      <td>imma keep it real with y’all i don’t think the...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1299361296400429057</td>\n",
       "      <td>@USER guess the #cult45 #trumpdrunkmorons can ...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1239350672782483456</td>\n",
       "      <td>joe “let’s be reasonable guys not everybody ca...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1299022276571140099</td>\n",
       "      <td>pelosi says biden shouldn't debate trump: 'i w...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295359993655578624</td>\n",
       "      <td>@USER hey @USER, here’s what your own party th...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1296637794966745088</td>\n",
       "      <td>i’m excited to hear from hunter biden’s family...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1295317559802302466</td>\n",
       "      <td>@USER your still talking about trump? get over...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1292661159078723590</td>\n",
       "      <td>@USER we will...thank you for checking\\n#biden...</td>\n",
       "      <td>FAVOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1298457178773184512</td>\n",
       "      <td>i thought you were not doing bad, but then the...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1301526342341726208</td>\n",
       "      <td>@USER exactly @USER !!! we all must vote in pe...</td>\n",
       "      <td>AGAINST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "0    1311162417938919424  imma keep it real with y’all i don’t think the...   \n",
       "1    1299361296400429057  @USER guess the #cult45 #trumpdrunkmorons can ...   \n",
       "2    1239350672782483456  joe “let’s be reasonable guys not everybody ca...   \n",
       "3    1299022276571140099  pelosi says biden shouldn't debate trump: 'i w...   \n",
       "4    1295359993655578624  @USER hey @USER, here’s what your own party th...   \n",
       "..                   ...                                                ...   \n",
       "870  1296637794966745088  i’m excited to hear from hunter biden’s family...   \n",
       "871  1295317559802302466  @USER your still talking about trump? get over...   \n",
       "872  1292661159078723590  @USER we will...thank you for checking\\n#biden...   \n",
       "873  1298457178773184512  i thought you were not doing bad, but then the...   \n",
       "874  1301526342341726208  @USER exactly @USER !!! we all must vote in pe...   \n",
       "\n",
       "       label  \n",
       "0       NONE  \n",
       "1       NONE  \n",
       "2       NONE  \n",
       "3    AGAINST  \n",
       "4       NONE  \n",
       "..       ...  \n",
       "870     NONE  \n",
       "871  AGAINST  \n",
       "872    FAVOR  \n",
       "873     NONE  \n",
       "874  AGAINST  \n",
       "\n",
       "[875 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb885dde-967b-4c2b-b2f8-e96b13e51db4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def stance_to_sentiment(stance):\n",
    "    if (stance == \"NONE\"): return 0\n",
    "    elif (stance == \"AGAINST\"): return -1\n",
    "    elif (stance == \"FAVOR\"): return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65141908-db54-4cf3-825a-9f28dca824be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dataset in all_datasets:\n",
    "    dataset[\"sentiment\"] = dataset[\"label\"].apply(stance_to_sentiment)\n",
    "    dataset[\"cleaned_text\"] = dataset[\"text\"].apply(clean_tweet)\n",
    "    dataset[\"lemmatized_text\"] = dataset[\"cleaned_text\"].apply(filter_stopwords_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04931195-ae9f-4d27-b480-37402aed3b8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imma keep it real with y’all i don’t think the...</td>\n",
       "      <td>imma keep it real with yall i dont think the  ...</td>\n",
       "      <td>imma keep real yall dont think twitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER guess the #cult45 #trumpdrunkmorons can ...</td>\n",
       "      <td>guess the   can pick their poison unlike jim ...</td>\n",
       "      <td>guess pick poison unlike jim jones offered one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joe “let’s be reasonable guys not everybody ca...</td>\n",
       "      <td>joe lets be reasonable guys not everybody can ...</td>\n",
       "      <td>joe let reasonable guy everybody get medicare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pelosi says biden shouldn't debate trump: 'i w...</td>\n",
       "      <td>pelosi says biden shouldnt debate trump i woul...</td>\n",
       "      <td>pelosi say biden shouldnt debate trump wouldnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER hey @USER, here’s what your own party th...</td>\n",
       "      <td>hey  heres what your own party thinks of you ...</td>\n",
       "      <td>hey here party think billboard paid world see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>i’m excited to hear from hunter biden’s family...</td>\n",
       "      <td>im excited to hear from hunter bidens family a...</td>\n",
       "      <td>im excited hear hunter bidens family http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>@USER your still talking about trump? get over...</td>\n",
       "      <td>your still talking about trump get over it so...</td>\n",
       "      <td>still talking trump get sonnyboy he going win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>@USER we will...thank you for checking\\n#biden...</td>\n",
       "      <td>we willthank you for checking\\n</td>\n",
       "      <td>willthank checking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>i thought you were not doing bad, but then the...</td>\n",
       "      <td>i thought you were not doing bad but then the ...</td>\n",
       "      <td>thought bad lie came like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>@USER exactly @USER !!! we all must vote in pe...</td>\n",
       "      <td>exactly   we all must vote in person for</td>\n",
       "      <td>exactly must vote person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    imma keep it real with y’all i don’t think the...   \n",
       "1    @USER guess the #cult45 #trumpdrunkmorons can ...   \n",
       "2    joe “let’s be reasonable guys not everybody ca...   \n",
       "3    pelosi says biden shouldn't debate trump: 'i w...   \n",
       "4    @USER hey @USER, here’s what your own party th...   \n",
       "..                                                 ...   \n",
       "870  i’m excited to hear from hunter biden’s family...   \n",
       "871  @USER your still talking about trump? get over...   \n",
       "872  @USER we will...thank you for checking\\n#biden...   \n",
       "873  i thought you were not doing bad, but then the...   \n",
       "874  @USER exactly @USER !!! we all must vote in pe...   \n",
       "\n",
       "                                          cleaned_text  \\\n",
       "0    imma keep it real with yall i dont think the  ...   \n",
       "1     guess the   can pick their poison unlike jim ...   \n",
       "2    joe lets be reasonable guys not everybody can ...   \n",
       "3    pelosi says biden shouldnt debate trump i woul...   \n",
       "4     hey  heres what your own party thinks of you ...   \n",
       "..                                                 ...   \n",
       "870  im excited to hear from hunter bidens family a...   \n",
       "871   your still talking about trump get over it so...   \n",
       "872                   we willthank you for checking\\n    \n",
       "873  i thought you were not doing bad but then the ...   \n",
       "874   exactly   we all must vote in person for           \n",
       "\n",
       "                                       lemmatized_text  \n",
       "0                imma keep real yall dont think twitch  \n",
       "1    guess pick poison unlike jim jones offered one...  \n",
       "2    joe let reasonable guy everybody get medicare ...  \n",
       "3    pelosi say biden shouldnt debate trump wouldnt...  \n",
       "4    hey here party think billboard paid world see ...  \n",
       "..                                                 ...  \n",
       "870          im excited hear hunter bidens family http  \n",
       "871      still talking trump get sonnyboy he going win  \n",
       "872                                 willthank checking  \n",
       "873                          thought bad lie came like  \n",
       "874                           exactly must vote person  \n",
       "\n",
       "[875 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_train[[\"text\", \"cleaned_text\", \"lemmatized_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012f19f-cdc4-421d-880e-efe4fb37ed91",
   "metadata": {},
   "source": [
    "# Uczenie modelu dla word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "42013f0f-f4d4-4b5e-8308-b63d17946f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71888b6d-b563-4732-bb39-99726fdac256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/word2vec.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "436a82cc-f3c0-4110-8e25-4623f6160cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0183195b-f26d-4aff-8cee-f34ed165d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1, probability=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9e001279-e7bf-4f8f-aaf6-cd7d73efb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d98d8e10-56df-46b3-af36-98b8055de6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    tokens = text.split()\n",
    "    vec = np.zeros(vec_size).reshape((1, vec_size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += w2v_model.wv[word].reshape((1, vec_size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e501099e-5154-41f1-b2f5-c3b49921b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_column_into_w2v_array(column):\n",
    "    wordvec_arrays = np.zeros((len(column), vec_size)) \n",
    "    for i in range(len(column)):\n",
    "        wordvec_arrays[i,:] = text_to_vector(column[i])\n",
    "    return pd.DataFrame(wordvec_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "621528d4-59b9-419d-8176-0ad06f7e2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_xtrain = text_column_into_w2v_array(biden_train[\"lemmatized_text\"]).iloc[:875,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "08e04119-c837-4505-bba3-1c321c6aefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_ytrain = biden_train[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dc81d9d8-4ac0-4f48-801c-7a5745540712",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_xtrain = text_column_into_w2v_array(trump_train[\"lemmatized_text\"]).iloc[:875,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9d5703fd-d5d2-45cc-9e8d-8953e6394b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_ytrain = trump_train[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "69c1fa40-38de-470f-aa3e-f08ff8943ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1784152378467374"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_lr = LinearRegression().fit(biden_xtrain, biden_ytrain)\n",
    "biden_lr.score(biden_xtrain, biden_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7edabd86-dc34-4859-982c-80ca6da4da0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16081632975601856"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_lr = LinearRegression().fit(trump_xtrain, trump_ytrain)\n",
    "trump_lr.score(trump_xtrain, trump_ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f6042-e7c2-4b07-8462-96e181cbec12",
   "metadata": {},
   "source": [
    "# Sprawdzenie poprawności działania regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e0904214-fc1b-4bb2-b1f2-3454cbb641e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_xtest = text_column_into_w2v_array(biden_test['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "69ae87f7-c265-4570-bead-a2069b1f8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_ytest = biden_test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "388277f7-23f5-47bd-a5ad-783e7a5dadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_xtest = text_column_into_w2v_array(trump_test['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2cd3f0ba-7b94-4b37-9f62-86965219ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_ytest = trump_test[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23b5a64c-b24a-42d3-ae47-c19cd9f3bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_class(number):\n",
    "    if number >= 0.1:\n",
    "        return 1\n",
    "    elif number <= -0.1:\n",
    "        return -1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0dd5e257-38f7-4560-8bb7-d64571badd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_for_model(model, x, y):\n",
    "    model_output = pd.DataFrame(model.predict(x))\n",
    "    model_output[\"classified\"] = output[0].apply(number_to_class)\n",
    "    return (y == model_output[\"classified\"]).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "002cdbed-e13d-45b6-b373-2bd82c16dc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37066666666666664"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy_for_model(biden_lr, biden_xtest, biden_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fcad071c-e650-4fcd-b846-6d4350c46738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29333333333333333"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy_for_model(trump_lr, trump_xtest, trump_ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c3770e-7335-4a22-bb51-d47126c580f6",
   "metadata": {},
   "source": [
    "# Zapis modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "66cacadb-fa47-4e8c-aeb3-2161ea2becaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9141bf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dump(biden_lr, '../models/biden_lr.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44549cb4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dump(trump_lr, '../models/trump_lr.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
